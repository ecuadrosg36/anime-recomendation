{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — Modelos de CF Explícito (Neural CF)\n",
    "\n",
    "Este cuaderno entrena un modelo **Neural Collaborative Filtering** \n",
    "(embeddings de usuario e ítem + MLP) sobre `rating_complete` (explícito)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\enman\\Downloads\\COLFONDOS\\DMC\\anime-recomendation\n"
     ]
    }
   ],
   "source": [
    "# Importación y rutas\n",
    "import sys\n",
    "from pathlib import Path\n",
    "repo_root = Path().resolve().parent if Path.cwd().name == \"notebooks\" else Path().resolve()\n",
    "sys.path.insert(0, str(repo_root))\n",
    "print(\"Repo root:\", repo_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization, Activation\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import polars as pl, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "processed = repo_root / \"data\" / \"processed\"\n",
    "ratings = pl.read_parquet(processed / \"rating_complete.parquet\")\n",
    "\n",
    "# Indexación (mapas user/item -> idx)\n",
    "users = ratings.select(\"user_id\").unique().with_row_count(\"uidx\")\n",
    "items = ratings.select(\"anime_id\").unique().with_row_count(\"iidx\")\n",
    "ui = (ratings.join(users, on=\"user_id\").join(items, on=\"anime_id\")\n",
    "            .select(\"uidx\",\"iidx\",\"score\"))\n",
    "\n",
    "n_users = int(users.height)\n",
    "n_items = int(items.height)\n",
    "print(\"n_users, n_items:\", n_users, n_items)\n",
    "\n",
    "Xu = ui[\"uidx\"].to_numpy()\n",
    "Xi = ui[\"iidx\"].to_numpy()\n",
    "y  = ui[\"score\"].to_numpy().astype(\"float32\")\n",
    "\n",
    "# Normalización básica 1..10 -> 0..1\n",
    "y_min, y_max = y.min(), y.max()\n",
    "y_norm = (y - y_min) / (y_max - y_min + 1e-9)\n",
    "\n",
    "X_train_u, X_test_u, X_train_i, X_test_i, y_train, y_test = train_test_split(\n",
    "    Xu, Xi, y_norm, test_size=0.1, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "def RecommenderNet(n_users, n_items, embedding_size=64, hidden=[128,64]):\n",
    "    u_in = Input(shape=(1,), name=\"u_in\")\n",
    "    i_in = Input(shape=(1,), name=\"i_in\")\n",
    "    u_emb = Embedding(n_users, embedding_size, name=\"u_emb\")(u_in)\n",
    "    i_emb = Embedding(n_items, embedding_size, name=\"i_emb\")(i_in)\n",
    "    u_vec = Flatten()(u_emb)\n",
    "    i_vec = Flatten()(i_emb)\n",
    "    x = Concatenate()([u_vec, i_vec])\n",
    "    for h in hidden:\n",
    "        x = Dense(h)(x); x = BatchNormalization()(x); x = Activation(\"relu\")(x); x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)  # pred en [0,1]\n",
    "    model = Model([u_in, i_in], out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "model = RecommenderNet(n_users, n_items)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = repo_root / \"models\"; ckpt.mkdir(exist_ok=True, parents=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(str(ckpt / \"ncf_best.keras\"), save_best_only=True, monitor=\"val_loss\", mode=\"min\"),\n",
    "    ReduceLROnPlateau(patience=2, factor=0.5, min_lr=1e-5)\n",
    "]\n",
    "\n",
    "hist = model.fit([X_train_u, X_train_i], y_train, \n",
    "    validation_data=([X_test_u, X_test_i], y_test),\n",
    "    epochs=5, batch_size=8192, callbacks=callbacks, verbose=1)\n",
    "\n",
    "# Evaluación (RMSE/MAE en la escala original)\n",
    "y_pred = model.predict([X_test_u, X_test_i], verbose=0).ravel()\n",
    "import numpy as np\n",
    "def rmse(a,b): return float(np.sqrt(np.mean((a-b)**2)))\n",
    "\n",
    "rmse_val = rmse(y_test, y_pred)\n",
    "mae_val = float(np.mean(np.abs(y_test - y_pred)))\n",
    "print(\"VAL (norm) RMSE:\", rmse_val, \"MAE:\", mae_val)\n",
    "\n",
    "# Desnormalizar si se desea comparar con [1..10]\n",
    "y_pred_denorm = y_pred * (y_max - y_min) + y_min\n",
    "y_test_denorm = y_test * (y_max - y_min) + y_min\n",
    "print(\"VAL (original) RMSE:\", rmse(y_test_denorm, y_pred_denorm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de recomendación para usuario dado\n",
    "import numpy as np\n",
    "\n",
    "def recommend_for_user(user_id_original, topk=10):\n",
    "    # mapear a índice\n",
    "    uidx = int(users.filter(pl.col(\"user_id\")==user_id_original)[\"uidx\"][0])\n",
    "    # puntuar todos los items\n",
    "    ii = np.arange(n_items, dtype=np.int32)\n",
    "    uu = np.full_like(ii, uidx)\n",
    "    scores = model.predict([uu, ii], verbose=0).ravel()\n",
    "    # excluir vistos\n",
    "    seen = set(ui.filter(pl.col(\"uidx\")==uidx)[\"iidx\"].to_list())\n",
    "    order = np.argsort(scores)[::-1]\n",
    "    recs = [int(i) for i in order if i not in seen][:topk]\n",
    "    # devolver ids originales\n",
    "    item_map = items.sort(\"iidx\")\n",
    "    return item_map.filter(pl.col(\"iidx\").is_in(recs))[\"anime_id\"].to_list()\n",
    "\n",
    "print(\"Ejemplo recomendaciones para el primer usuario:\", recommend_for_user(users['user_id'][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gpu (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
